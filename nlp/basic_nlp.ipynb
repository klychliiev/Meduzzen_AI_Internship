{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1447b066000>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Convert a string containing human language text into lists of sentences and words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The sun peeked through the clouds, casting a warm glow over the tranquil meadow. \\\n",
    "Birds chirped melodiously, creating a symphony that echoed through the trees. \\\n",
    "The scent of freshly cut grass mingled with the sweet fragrance of blooming flowers, \\\n",
    "creating a delightful aroma in the air. A gentle breeze danced through the leaves, \\\n",
    "causing them to rustle softly. In that serene moment, everything felt harmonious and alive, embracing the beauty of nature.\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "doc = text\n",
    "doc_nlp = nlp(doc)\n",
    "\n",
    "print(type(doc))\n",
    "print(type(doc_nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'sun',\n",
       " 'peeked',\n",
       " 'through',\n",
       " 'the',\n",
       " 'clouds',\n",
       " ',',\n",
       " 'casting',\n",
       " 'a',\n",
       " 'warm',\n",
       " 'glow',\n",
       " 'over',\n",
       " 'the',\n",
       " 'tranquil',\n",
       " 'meadow',\n",
       " '.',\n",
       " 'Birds',\n",
       " 'chirped',\n",
       " 'melodiously',\n",
       " ',',\n",
       " 'creating',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'that',\n",
       " 'echoed',\n",
       " 'through',\n",
       " 'the',\n",
       " 'trees',\n",
       " '.',\n",
       " 'The',\n",
       " 'scent',\n",
       " 'of',\n",
       " 'freshly',\n",
       " 'cut',\n",
       " 'grass',\n",
       " 'mingled',\n",
       " 'with',\n",
       " 'the',\n",
       " 'sweet',\n",
       " 'fragrance',\n",
       " 'of',\n",
       " 'blooming',\n",
       " 'flowers',\n",
       " ',',\n",
       " 'creating',\n",
       " 'a',\n",
       " 'delightful',\n",
       " 'aroma',\n",
       " 'in',\n",
       " 'the',\n",
       " 'air',\n",
       " '.',\n",
       " 'A',\n",
       " 'gentle',\n",
       " 'breeze',\n",
       " 'danced',\n",
       " 'through',\n",
       " 'the',\n",
       " 'leaves',\n",
       " ',',\n",
       " 'causing',\n",
       " 'them',\n",
       " 'to',\n",
       " 'rustle',\n",
       " 'softly',\n",
       " '.',\n",
       " 'In',\n",
       " 'that',\n",
       " 'serene',\n",
       " 'moment',\n",
       " ',',\n",
       " 'everything',\n",
       " 'felt',\n",
       " 'harmonious',\n",
       " 'and',\n",
       " 'alive',\n",
       " ',',\n",
       " 'embracing',\n",
       " 'the',\n",
       " 'beauty',\n",
       " 'of',\n",
       " 'nature',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc_nlp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sun peeked through the clouds, casting a warm glow over the tranquil meadow. Birds chirped melodiously, creating a symphony that echoed through the trees. The scent of freshly cut grass mingled with the sweet fragrance of blooming flowers, creating a delightful aroma in the air. A gentle breeze danced through the leaves, causing them to rustle softly. In that serene moment, everything felt harmonious and alive, embracing the beauty of nature.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"The sun peeked through the clouds, casting a warm glow over the tranquil meadow. \\\n",
    "Birds chirped melodiously, creating a symphony that echoed through the trees. \\\n",
    "The scent of freshly cut grass mingled with the sweet fragrance of blooming flowers, \\\n",
    "creating a delightful aroma in the air. A gentle breeze danced through the leaves, \\\n",
    "causing them to rustle softly. In that serene moment, everything felt harmonious and alive, embracing the beauty of nature.\"\"\" \n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nlp = nlp(text)\n",
    "sentences = list(text_nlp.sents)\n",
    "\n",
    "# number of sentences in our string\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The sun peeked through the clouds, casting a warm glow over the tranquil meadow.\n",
      "2. Birds chirped melodiously, creating a symphony that echoed through the trees.\n",
      "3. The scent of freshly cut grass mingled with the sweet fragrance of blooming flowers, creating a delightful aroma in the air.\n",
      "4. A gentle breeze danced through the leaves, causing them to rustle softly.\n",
      "5. In that serene moment, everything felt harmonious and alive, embracing the beauty of nature.\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(sentences):\n",
    "    print(f\"{idx+1}.\" ,sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index positioning \n",
    "\n",
    "data = []\n",
    "\n",
    "for token in text_nlp:\n",
    "    to_add = (token, token.idx, token.is_alpha, token.is_stop)\n",
    "    data.append(to_add) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(The, 0, True, True),\n",
       " (sun, 4, True, False),\n",
       " (peeked, 8, True, False),\n",
       " (through, 15, True, True),\n",
       " (the, 23, True, True),\n",
       " (clouds, 27, True, False),\n",
       " (,, 33, False, False),\n",
       " (casting, 35, True, False),\n",
       " (a, 43, True, True),\n",
       " (warm, 45, True, False),\n",
       " (glow, 50, True, False),\n",
       " (over, 55, True, True),\n",
       " (the, 60, True, True),\n",
       " (tranquil, 64, True, False),\n",
       " (meadow, 73, True, False),\n",
       " (., 79, False, False),\n",
       " (Birds, 81, True, False),\n",
       " (chirped, 87, True, False),\n",
       " (melodiously, 95, True, False),\n",
       " (,, 106, False, False),\n",
       " (creating, 108, True, False),\n",
       " (a, 117, True, True),\n",
       " (symphony, 119, True, False),\n",
       " (that, 128, True, True),\n",
       " (echoed, 133, True, False),\n",
       " (through, 140, True, True),\n",
       " (the, 148, True, True),\n",
       " (trees, 152, True, False),\n",
       " (., 157, False, False),\n",
       " (The, 159, True, True),\n",
       " (scent, 163, True, False),\n",
       " (of, 169, True, True),\n",
       " (freshly, 172, True, False),\n",
       " (cut, 180, True, False),\n",
       " (grass, 184, True, False),\n",
       " (mingled, 190, True, False),\n",
       " (with, 198, True, True),\n",
       " (the, 203, True, True),\n",
       " (sweet, 207, True, False),\n",
       " (fragrance, 213, True, False),\n",
       " (of, 223, True, True),\n",
       " (blooming, 226, True, False),\n",
       " (flowers, 235, True, False),\n",
       " (,, 242, False, False),\n",
       " (creating, 244, True, False),\n",
       " (a, 253, True, True),\n",
       " (delightful, 255, True, False),\n",
       " (aroma, 266, True, False),\n",
       " (in, 272, True, True),\n",
       " (the, 275, True, True),\n",
       " (air, 279, True, False),\n",
       " (., 282, False, False),\n",
       " (A, 284, True, True),\n",
       " (gentle, 286, True, False),\n",
       " (breeze, 293, True, False),\n",
       " (danced, 300, True, False),\n",
       " (through, 307, True, True),\n",
       " (the, 315, True, True),\n",
       " (leaves, 319, True, False),\n",
       " (,, 325, False, False),\n",
       " (causing, 327, True, False),\n",
       " (them, 335, True, True),\n",
       " (to, 340, True, True),\n",
       " (rustle, 343, True, False),\n",
       " (softly, 350, True, False),\n",
       " (., 356, False, False),\n",
       " (In, 358, True, True),\n",
       " (that, 361, True, True),\n",
       " (serene, 366, True, False),\n",
       " (moment, 373, True, False),\n",
       " (,, 379, False, False),\n",
       " (everything, 381, True, True),\n",
       " (felt, 392, True, False),\n",
       " (harmonious, 397, True, False),\n",
       " (and, 408, True, True),\n",
       " (alive, 412, True, False),\n",
       " (,, 417, False, False),\n",
       " (embracing, 419, True, False),\n",
       " (the, 429, True, True),\n",
       " (beauty, 433, True, False),\n",
       " (of, 440, True, True),\n",
       " (nature, 443, True, False),\n",
       " (., 449, False, False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tuples\n",
    "# 1st item in a tuple is each token in the text, 2d - starting index of this token\n",
    "# 3d - if a token is alphabetical (word), 4th - if a token is a stop word\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "columns = ['token', 'start_index', 'is_alpha', 'is_stop_word']\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>start_index</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peeked</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>through</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>the</td>\n",
       "      <td>429</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>beauty</td>\n",
       "      <td>433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>of</td>\n",
       "      <td>440</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>nature</td>\n",
       "      <td>443</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>.</td>\n",
       "      <td>449</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  start_index  is_alpha  is_stop_word\n",
       "0       The            0      True          True\n",
       "1       sun            4      True         False\n",
       "2    peeked            8      True         False\n",
       "3   through           15      True          True\n",
       "4       the           23      True          True\n",
       "..      ...          ...       ...           ...\n",
       "78      the          429      True          True\n",
       "79   beauty          433      True         False\n",
       "80       of          440      True          True\n",
       "81   nature          443      True         False\n",
       "82        .          449     False         False\n",
       "\n",
       "[83 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.fr import stop_words as french_stop_words\n",
    "\n",
    "french_stop_words = french_stop_words.STOP_WORDS\n",
    "\n",
    "# number of French stop words\n",
    "len(french_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.de import stop_words as german_stop_words\n",
    "\n",
    "german_stop_words = german_stop_words.STOP_WORDS\n",
    "\n",
    "# number of German stop words\n",
    "len(german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darfst\n",
      "hier\n",
      "teil\n",
      "ihrem\n",
      "allen\n",
      "sowie\n",
      "bald\n",
      "eben\n",
      "hat\n",
      "sich\n",
      "deine\n",
      "über\n",
      "diesem\n",
      "dabei\n",
      "gehabt\n",
      "wenige\n",
      "dürfen\n",
      "aller\n",
      "geworden\n",
      "drei\n",
      "dagegen\n",
      "elf\n",
      "ging\n",
      "erstes\n",
      "drittes\n",
      "oder\n",
      "wer\n",
      "kleine\n",
      "sie\n",
      "für\n",
      "ich\n",
      "man\n",
      "ihm\n",
      "gemusst\n",
      "derjenige\n",
      "jahren\n",
      "schlecht\n",
      "zweites\n",
      "seit\n",
      "hätte\n",
      "zwar\n",
      "infolgedessen\n",
      "jetzt\n",
      "demgegenüber\n",
      "ihr\n",
      "haben\n",
      "dieses\n",
      "tag\n",
      "konnte\n",
      "sollten\n",
      "einiger\n",
      "solchen\n",
      "gewesen\n",
      "soll\n",
      "dazwischen\n",
      "zunächst\n",
      "sei\n",
      "darf\n",
      "jemanden\n",
      "also\n",
      "in\n",
      "an\n",
      "beispiel\n",
      "daher\n",
      "danach\n",
      "auch\n",
      "es\n",
      "diese\n",
      "gibt\n",
      "mancher\n",
      "großer\n",
      "ausser\n",
      "unsere\n",
      "gar\n",
      "oft\n",
      "daraus\n",
      "ganze\n",
      "keine\n",
      "tat\n",
      "werde\n",
      "siebenter\n",
      "einer\n",
      "siebte\n",
      "dafür\n",
      "sechstes\n",
      "muss\n",
      "dahinter\n",
      "während\n",
      "gesagt\n",
      "daselbst\n",
      "jedem\n",
      "los\n",
      "zwanzig\n",
      "ihnen\n",
      "hinter\n",
      "achten\n",
      "mir\n",
      "niemand\n",
      "einmaleins\n",
      "drin\n",
      "meiner\n",
      "dasselbe\n",
      "nicht\n",
      "niemanden\n",
      "rechte\n",
      "nun\n",
      "auf\n",
      "statt\n",
      "wir\n",
      "trotzdem\n",
      "wo\n",
      "dieser\n",
      "fünf\n",
      "bekannt\n",
      "einem\n",
      "gute\n",
      "ausserdem\n",
      "derjenigen\n",
      "welches\n",
      "zuerst\n",
      "dieselben\n",
      "wurden\n",
      "gedurft\n",
      "dritte\n",
      "etwas\n",
      "ganzer\n",
      "deinem\n",
      "würden\n",
      "darüber\n",
      "zwei\n",
      "deiner\n",
      "manches\n",
      "zugleich\n",
      "keiner\n",
      "solcher\n",
      "anders\n",
      "jene\n",
      "sollen\n",
      "wie\n",
      "damals\n",
      "dem\n",
      "und\n",
      "offen\n",
      "schon\n",
      "eigene\n",
      "von\n",
      "gut\n",
      "macht\n",
      "demzufolge\n",
      "dies\n",
      "sondern\n",
      "damit\n",
      "weil\n",
      "jemand\n",
      "vor\n",
      "siebtes\n",
      "seitdem\n",
      "wurde\n",
      "zwischen\n",
      "andern\n",
      "jener\n",
      "gern\n",
      "geschweige\n",
      "sollte\n",
      "weniger\n",
      "deshalb\n",
      "erster\n",
      "seien\n",
      "hatte\n",
      "rechten\n",
      "jahr\n",
      "gegen\n",
      "grossen\n",
      "fünfte\n",
      "recht\n",
      "denen\n",
      "vielem\n",
      "dir\n",
      "ihre\n",
      "zweite\n",
      "machte\n",
      "will\n",
      "wollt\n",
      "jahre\n",
      "sechsten\n",
      "jedoch\n",
      "beim\n",
      "derselben\n",
      "zehnten\n",
      "waren\n",
      "dein\n",
      "habt\n",
      "mögt\n",
      "gutes\n",
      "vier\n",
      "war\n",
      "manche\n",
      "daß\n",
      "darunter\n",
      "mussten\n",
      "eigener\n",
      "nichts\n",
      "achte\n",
      "heisst\n",
      "wird\n",
      "wirst\n",
      "erste\n",
      "nachdem\n",
      "eine\n",
      "wollen\n",
      "diejenige\n",
      "demgemäß\n",
      "ja\n",
      "ohne\n",
      "jeden\n",
      "anderem\n",
      "davon\n",
      "als\n",
      "ganz\n",
      "beide\n",
      "worden\n",
      "sechster\n",
      "immer\n",
      "mit\n",
      "viel\n",
      "ein\n",
      "genug\n",
      "indem\n",
      "dich\n",
      "währenddem\n",
      "mittel\n",
      "ehrlich\n",
      "um\n",
      "dazu\n",
      "selbst\n",
      "wollte\n",
      "musst\n",
      "welchem\n",
      "gross\n",
      "entweder\n",
      "ob\n",
      "kleiner\n",
      "kommen\n",
      "solchem\n",
      "nein\n",
      "vielen\n",
      "beiden\n",
      "welche\n",
      "meines\n",
      "allein\n",
      "durch\n",
      "grosse\n",
      "weiter\n",
      "wegen\n",
      "aus\n",
      "unter\n",
      "zehnte\n",
      "was\n",
      "dadurch\n",
      "gehen\n",
      "im\n",
      "seines\n",
      "tagen\n",
      "lange\n",
      "du\n",
      "ersten\n",
      "jemandem\n",
      "allem\n",
      "das\n",
      "eigen\n",
      "wann\n",
      "demgemäss\n",
      "euch\n",
      "uns\n",
      "unserer\n",
      "vergangenen\n",
      "vielleicht\n",
      "jenen\n",
      "vierten\n",
      "ihren\n",
      "da\n",
      "dritter\n",
      "gleich\n",
      "eigenen\n",
      "viele\n",
      "dessen\n",
      "gekannt\n",
      "durften\n",
      "zur\n",
      "wollten\n",
      "je\n",
      "dermaßen\n",
      "kleines\n",
      "daneben\n",
      "allerdings\n",
      "dermassen\n",
      "wieder\n",
      "müsst\n",
      "hast\n",
      "so\n",
      "nahm\n",
      "durchaus\n",
      "mehr\n",
      "vergangene\n",
      "manchem\n",
      "wem\n",
      "alles\n",
      "einigen\n",
      "siebten\n",
      "nach\n",
      "willst\n",
      "jeder\n",
      "derselbe\n",
      "mich\n",
      "tun\n",
      "seinem\n",
      "bisher\n",
      "morgen\n",
      "wirklich\n",
      "neuen\n",
      "weitere\n",
      "sechs\n",
      "neunte\n",
      "allgemeinen\n",
      "jenem\n",
      "außerdem\n",
      "leicht\n",
      "vom\n",
      "etwa\n",
      "guter\n",
      "nur\n",
      "weiteren\n",
      "wohl\n",
      "müssen\n",
      "neuntes\n",
      "bin\n",
      "viertes\n",
      "dritten\n",
      "ihrer\n",
      "zehn\n",
      "zum\n",
      "bei\n",
      "leider\n",
      "endlich\n",
      "uhr\n",
      "bereits\n",
      "kaum\n",
      "siebentes\n",
      "sah\n",
      "en\n",
      "zehnter\n",
      "sein\n",
      "erst\n",
      "diejenigen\n",
      "dank\n",
      "ist\n",
      "unser\n",
      "grosses\n",
      "des\n",
      "großes\n",
      "sagt\n",
      "könnte\n",
      "kannst\n",
      "deswegen\n",
      "kein\n",
      "eigenes\n",
      "ach\n",
      "manchen\n",
      "tel\n",
      "später\n",
      "oben\n",
      "ag\n",
      "möchte\n",
      "neunter\n",
      "rechter\n",
      "weiteres\n",
      "diesen\n",
      "gemocht\n",
      "weniges\n",
      "darin\n",
      "solches\n",
      "hatten\n",
      "können\n",
      "geht\n",
      "die\n",
      "wäre\n",
      "seinen\n",
      "sehr\n",
      "denn\n",
      "solang\n",
      "seine\n",
      "warum\n",
      "habe\n",
      "welchen\n",
      "vierte\n",
      "andere\n",
      "am\n",
      "wen\n",
      "könnt\n",
      "zurück\n",
      "früher\n",
      "fünfter\n",
      "groß\n",
      "doch\n",
      "möglich\n",
      "werden\n",
      "irgend\n",
      "desselben\n",
      "außer\n",
      "kurz\n",
      "mögen\n",
      "meine\n",
      "kann\n",
      "keinem\n",
      "kommt\n",
      "dasein\n",
      "großen\n",
      "demselben\n",
      "welcher\n",
      "gab\n",
      "heißt\n",
      "meinen\n",
      "dürft\n",
      "zweiten\n",
      "ihn\n",
      "siebter\n",
      "einander\n",
      "wart\n",
      "gewollt\n",
      "solche\n",
      "ganzen\n",
      "besten\n",
      "keinen\n",
      "denselben\n",
      "ab\n",
      "magst\n",
      "durfte\n",
      "mein\n",
      "dahin\n",
      "her\n",
      "überhaupt\n",
      "neun\n",
      "wenig\n",
      "seiner\n",
      "eines\n",
      "natürlich\n",
      "na\n",
      "tage\n",
      "jenes\n",
      "wahr\n",
      "alle\n",
      "daran\n",
      "gerade\n",
      "meinem\n",
      "wessen\n",
      "ebenso\n",
      "grosser\n",
      "neben\n",
      "davor\n",
      "er\n",
      "sind\n",
      "weit\n",
      "große\n",
      "werdet\n",
      "hätten\n",
      "besonders\n",
      "seid\n",
      "machen\n",
      "acht\n",
      "rechtes\n",
      "zehntes\n",
      "darum\n",
      "muß\n",
      "richtig\n",
      "satt\n",
      "mag\n",
      "gemacht\n",
      "zu\n",
      "einige\n",
      "mochte\n",
      "übrigens\n",
      "gegenüber\n",
      "ins\n",
      "aber\n",
      "jede\n",
      "einiges\n",
      "dann\n",
      "der\n",
      "einmal\n",
      "zusammen\n",
      "achtes\n",
      "neue\n",
      "gekonnt\n",
      "hin\n",
      "anderen\n",
      "jedermanns\n",
      "heute\n",
      "bis\n",
      "lang\n",
      "ihres\n",
      "bist\n",
      "dort\n",
      "fünftes\n",
      "hoch\n",
      "vierter\n",
      "sechste\n",
      "nie\n",
      "lieber\n",
      "kleinen\n",
      "einen\n",
      "sagte\n",
      "währenddessen\n",
      "neunten\n",
      "siebenten\n",
      "ende\n",
      "jedermann\n",
      "den\n",
      "zweiter\n",
      "achter\n",
      "rund\n",
      "würde\n",
      "wenn\n",
      "mochten\n",
      "sonst\n",
      "siebente\n",
      "dieselbe\n",
      "sieben\n",
      "besser\n",
      "ganzes\n",
      "noch\n",
      "dementsprechend\n",
      "deren\n",
      "zeit\n",
      "konnten\n",
      "á\n",
      "kam\n",
      "niemandem\n",
      "dass\n",
      "fünften\n",
      "musste\n",
      "wenigstens\n",
      "darauf\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for word in german_stop_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_sent = \"Le chat noir se promène silencieusement dans le jardin sous la lune brillante.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Generate base forms of those words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lemmatization</b> is the process of reducing inflected forms of a word while still ensuring that the reduced form belongs to the language. This reduced form, or root word, is called a lemma.\n",
    "For example, words <em>was, were, been, being</em> are all forms of the lemma <em>be</em>. While the lemma table has the following paradigm in the English language: table, tables, table's and tables'.\n",
    "English is not highly inflected language, unlike, for instance, Slavic languages. Ukrainian noun paradigm includes 14 words forms, adjective and verb paradigms - 24 each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              peeked : peek\n",
      "              clouds : cloud\n",
      "             casting : cast\n"
     ]
    }
   ],
   "source": [
    "for token in text_nlp[:10]:\n",
    "    if str(token).lower() != str(token.lemma_):\n",
    "        # print only if the word form is different from lemma\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Detect parts of speech and morphological features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_info = []\n",
    "\n",
    "for token in text_nlp:\n",
    "    tup = (str(token), str(token.lemma_), str(token.tag_), token.pos_, spacy.explain(token.tag_), token.morph.to_dict())\n",
    "    morph_info.append(tup)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".tag_ displays a fine-grained tag <br>\n",
    ".pos_ displays a coarse-grained tagm which is the reduced version of the fine-grained tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_explanation</th>\n",
       "      <th>morph_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>{'Definite': 'Def', 'PronType': 'Art'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "      <td>{'Number': 'Sing'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peeked</td>\n",
       "      <td>peek</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb, past tense</td>\n",
       "      <td>{'Tense': 'Past', 'VerbForm': 'Fin'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>through</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>{'Definite': 'Def', 'PronType': 'Art'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>{'Definite': 'Def', 'PronType': 'Art'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>beauty</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "      <td>{'Number': 'Sing'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>nature</td>\n",
       "      <td>nature</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "      <td>{'Number': 'Sing'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "      <td>{'PunctType': 'Peri'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    lemma  tag    pos                            tag_explanation  \\\n",
       "0       The      the   DT    DET                                 determiner   \n",
       "1       sun      sun   NN   NOUN                     noun, singular or mass   \n",
       "2    peeked     peek  VBD   VERB                           verb, past tense   \n",
       "3   through  through   IN    ADP  conjunction, subordinating or preposition   \n",
       "4       the      the   DT    DET                                 determiner   \n",
       "..      ...      ...  ...    ...                                        ...   \n",
       "78      the      the   DT    DET                                 determiner   \n",
       "79   beauty   beauty   NN   NOUN                     noun, singular or mass   \n",
       "80       of       of   IN    ADP  conjunction, subordinating or preposition   \n",
       "81   nature   nature   NN   NOUN                     noun, singular or mass   \n",
       "82        .        .    .  PUNCT          punctuation mark, sentence closer   \n",
       "\n",
       "                            morph_features  \n",
       "0   {'Definite': 'Def', 'PronType': 'Art'}  \n",
       "1                       {'Number': 'Sing'}  \n",
       "2     {'Tense': 'Past', 'VerbForm': 'Fin'}  \n",
       "3                                        -  \n",
       "4   {'Definite': 'Def', 'PronType': 'Art'}  \n",
       "..                                     ...  \n",
       "78  {'Definite': 'Def', 'PronType': 'Art'}  \n",
       "79                      {'Number': 'Sing'}  \n",
       "80                                       -  \n",
       "81                      {'Number': 'Sing'}  \n",
       "82                   {'PunctType': 'Peri'}  \n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['token', 'lemma', 'tag', 'pos', 'tag_explanation', 'morph_features']\n",
    "df = pd.DataFrame(morph_info, columns=columns)\n",
    "df.loc[df.morph_features == {}, 'morph_features'] = '-'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Dependency parsing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
